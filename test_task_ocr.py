# -*- coding: utf-8 -*-
"""Test_Task_OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16jHh3q6GPnN5XZF_I2dkx48w3e6si-Co
"""

# OCR Waybill Notebook

#Install dependencies (uncomment if running in Colab)
!apt install tesseract-ocr
!pip install pytesseract easyocr opencv-python matplotlib pandas

!pip install opencv-python pytesseract easyocr pandas matplotlib numpy scikit-image

#Imports
import os
import cv2
import numpy as np
import pytesseract
import re
import json
import pandas as pd
from skimage import exposure
import matplotlib.pyplot as plt
from typing import List, Tuple, Dict, Optional

# Optionally use EasyOCR (often gives improved results)
try:
    import easyocr
    _EASYOCR_AVAILABLE = True
except Exception:
    _EASYOCR_AVAILABLE = False

#Utility: display image in notebook
def imshow_rgb(img_bgr, figsize=(10,6), title=None):
    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=figsize)
    plt.imshow(img)
    plt.axis('off')
    if title: plt.title(title)
    plt.show()

#Preprocessing helpers
def resize_to_width(img, target_w=1600):
    h, w = img.shape[:2]
    if w == 0:
        return img
    if w >= target_w:
        return img
    scale = target_w / float(w)
    return cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)


def deskew_image(gray: np.ndarray) -> np.ndarray:
    # deskew works on binary or gray images
    coords = np.column_stack(np.where(gray < 255))
    if coords.size == 0:
        return gray
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = gray.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
    rotated = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated


def adaptive_contrast(img_gray: np.ndarray) -> np.ndarray:
    # simple contrast stretching
    p2, p98 = np.percentile(img_gray, (2, 98))
    return exposure.rescale_intensity(img_gray, in_range=(p2, p98))


def preprocess_image_for_ocr(img_bgr: np.ndarray, target_width=1600) -> np.ndarray:
    """Returns a binary (thresholded) image ready for OCR"""
    img = resize_to_width(img_bgr, target_width)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = adaptive_contrast(gray)
    # denoise
    gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
    # adaptive threshold
    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 15, 9)
    # optional morphological closing to fill small holes
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))
    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)
    th = deskew_image(th)
    return th

#Tesseract-based line extraction

def extract_lines_tesseract(image, lang=None, tesseract_config='--oem 3 --psm 6') -> List[Dict]:
    """Uses pytesseract.image_to_data to extract line-grouped text.
    Returns list of dicts with keys: text, left, top, width, height
    """
    data = pytesseract.image_to_data(image, lang=lang, config=tesseract_config, output_type=pytesseract.Output.DICT)
    n = len(data['level'])
    lines = {}
    for i in range(n):
        word = data['text'][i].strip()
        if word == '':
            continue
        key = (data['block_num'][i], data['par_num'][i], data['line_num'][i])
        left, top, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
        if key not in lines:
            lines[key] = {'words': [], 'left': left, 'top': top, 'right': left + w, 'bottom': top + h}
        lines[key]['words'].append((data['word_num'][i], word))
        lines[key]['left'] = min(lines[key]['left'], left)
        lines[key]['top'] = min(lines[key]['top'], top)
        lines[key]['right'] = max(lines[key]['right'], left + w)
        lines[key]['bottom'] = max(lines[key]['bottom'], top + h)
    out = []
    # sort lines top-to-bottom
    for k, v in sorted(lines.items(), key=lambda kv: (kv[1]['top'], kv[1]['left'])):
        words_sorted = [w for _, w in sorted(v['words'], key=lambda x: x[0])]
        full_line = ' '.join(words_sorted)
        out.append({'text': full_line, 'left': v['left'], 'top': v['top'],
                    'width': v['right'] - v['left'], 'height': v['bottom'] - v['top']})
    return out

#EasyOCR-based extraction (optional)

def extract_with_easyocr(img_bgr, reader=None, batch_size=32, allowlist=None):
    if not _EASYOCR_AVAILABLE:
        raise RuntimeError('EasyOCR not available. pip install easyocr')
    if reader is None:
        # English is default; add languages as needed e.g. ['en']
        reader = easyocr.Reader(['en'], gpu=False)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    results = reader.readtext(img_rgb, detail=1, batch_size=batch_size)
    # results: list of (bbox, text, confidence)
    out = []
    for bbox, text, conf in results:
        # bbox is 4 points; compute bounding box
        xs = [int(p[0]) for p in bbox]
        ys = [int(p[1]) for p in bbox]
        left, top = min(xs), min(ys)
        width, height = max(xs)-left, max(ys)-top
        out.append({'text': text, 'left': left, 'top': top, 'width': width, 'height': height, 'conf': conf})
    # We can merge nearby boxes into lines later if needed
    return out

#Line finding using pattern "_1_" with fuzzy fallbacks

def normalize_string(s: str) -> str:
    s = s or ''
    s = s.strip()
    s = re.sub(r'\s+', ' ', s)
    return s


def find_line_with_pattern(lines: List[Dict], pattern_literal: str = '_1_') -> Tuple[Optional[str], Optional[Dict]]:
    # 1) exact match
    for ln in lines:
        if pattern_literal in ln['text']:
            return ln['text'], ln
    # 2) normalized match (collapse spaces around underscores etc.)
    def norm(s):
        s2 = s.replace('–', '-').replace('—', '-')
        s2 = re.sub(r'\s*_\s*', '_', s2)
        s2 = re.sub(r'\s+', ' ', s2).strip()
        return s2
    pnorm = norm(pattern_literal)
    for ln in lines:
        if pnorm in norm(ln['text']):
            return ln['text'], ln
    # 3) fuzzy regex: allow hyphens or underscores around 1 with optional letters after
    fuzzy_re = re.compile(r'[_\-\u2010-\u2015]{0,2}\s*1\s*[_\-\u2010-\u2015]{0,2}')
    for ln in lines:
        if fuzzy_re.search(ln['text']):
            return ln['text'], ln
    return None, None

#Utility: merge line snippets into a set of cleaned lines

def merge_and_group_lines(detections: List[Dict], y_tol=10) -> List[Dict]:
    """Take word/box detections and group into lines by vertical overlap/proximity.
    Useful when using easyocr which returns many small boxes.
    """
    if not detections:
        return []
    # sort by top coordinate
    dets = sorted(detections, key=lambda x: x['top'])
    groups = []
    for d in dets:
        placed = False
        for g in groups:
            # if vertical overlap (or close)
            if abs(d['top'] - g['top']) <= y_tol:
                g['items'].append(d)
                g['top'] = min(g['top'], d['top'])
                g['left'] = min(g['left'], d['left'])
                g['right'] = max(g.get('right', d['left'] + d['width']), d['left'] + d['width'])
                placed = True
                break
        if not placed:
            groups.append({'top': d['top'], 'items': [d], 'left': d['left'], 'right': d['left'] + d['width']})
    out_lines = []
    for g in groups:
        # sort by left to assemble line text
        items_sorted = sorted(g['items'], key=lambda x: x['left'])
        texts = [normalize_string(it.get('text','')) for it in items_sorted]
        full = ' '.join([t for t in texts if t])
        out_lines.append({'text': full, 'left': g['left'], 'top': g['top'], 'width': g['right']-g['left'], 'height': 0})
    # final sort
    out_lines = sorted(out_lines, key=lambda x: (x['top'], x['left']))
    return out_lines

#Inference over a folder

def infer_folder(input_dir: str, out_json: str = 'predictions.json', use_easyocr: bool = False,
                 pattern: str = '_1_', lang: Optional[str]=None, target_width:int=1600):
    preds = []
    reader = None
    if use_easyocr:
        if not _EASYOCR_AVAILABLE:
            raise RuntimeError('easyocr not installed')
        reader = easyocr.Reader(['en'], gpu=False)
    for fname in sorted(os.listdir(input_dir)):
        if not fname.lower().endswith(('.jpg','.jpeg','.png','.tif','.tiff')):
            continue
        path = os.path.join(input_dir, fname)
        img = cv2.imread(path)
        if img is None:
            print('Could not read:', path)
            continue
        pre = preprocess_image_for_ocr(img, target_width=target_width)
        # For Tesseract we pass the thresholded image; for EasyOCR pass original
        if use_easyocr:
            dets = extract_with_easyocr(img, reader=reader)
            lines = merge_and_group_lines(dets)
        else:
            lines = extract_lines_tesseract(pre, lang=lang)
        text, meta = find_line_with_pattern(lines, pattern_literal=pattern)
        preds.append({'filename': fname, 'predicted_line': text if text else ''})
    with open(out_json, 'w', encoding='utf-8') as f:
        json.dump(preds, f, indent=2, ensure_ascii=False)
    print(f'Saved {len(preds)} predictions to {out_json}')
    return preds

#Evaluation

def normalize_for_eval(s: Optional[str]) -> str:
    if s is None: return ''
    s = s.strip()
    s = re.sub(r'\s+', ' ', s)
    s = s.lower()
    return s


def evaluate_predictions(gt_csv: str, pred_json: str) -> Tuple[float, pd.DataFrame]:
    gt = pd.read_csv(gt_csv, dtype=str).fillna('')
    preds = json.load(open(pred_json, 'r', encoding='utf-8'))
    pred_df = pd.DataFrame(preds)
    merged = gt.merge(pred_df, how='left', left_on='filename', right_on='filename')
    merged['predicted_line'] = merged['predicted_line'].fillna('')
    merged['gt_norm'] = merged['groundtruth_line'].apply(normalize_for_eval)
    merged['pred_norm'] = merged['predicted_line'].apply(normalize_for_eval)
    merged['correct'] = merged['gt_norm'] == merged['pred_norm']
    acc = merged['correct'].mean()
    print(f'Total: {len(merged)}, Correct: {merged["correct"].sum()}, Accuracy: {acc:.3f}')
    return acc, merged

#Visualization helpers to inspect failures
def show_failure_examples(merged_df: pd.DataFrame, folder: str, n: int = 10):
    fails = merged_df[~merged_df['correct']]
    for idx, row in fails.head(n).iterrows():
        fname = row['filename']
        gt = row['groundtruth_line']
        pred = row['predicted_line']
        path = os.path.join(folder, fname)
        img = cv2.imread(path)
        print(f'File: {fname}\nGT: {gt}\nPRED: {pred}\n---')
        if img is not None:
            imshow_rgb(img, figsize=(8,6))

INPUT_DIR = '/content/drive/MyDrive/KriraAI_Task/Test_Task_OCR/ReverseWay_Bill'
OUT_JSON = 'predictions.json'
#GT_CSV = 'groundtruth.csv'  # csv with columns: filename, groundtruth_line

# Run inference with Tesseract baseline
infer_folder(INPUT_DIR, out_json=OUT_JSON, use_easyocr=False, pattern='_1_')

# Evaluate
acc, merged = evaluate_predictions(GT_CSV, OUT_JSON)
show_failure_examples(merged, INPUT_DIR, n=10)

import pandas as pd
from src.evaluate import evaluate_dataset
from src.preprocessing import preprocess_image_bgr

df = pd.read_csv("ground_truth.csv")
image_paths = df['image_path'].tolist()
gts = df['ground_truth'].tolist()
res = evaluate_dataset(image_paths, gts, preprocess_fn=preprocess_image_bgr)
print("Accuracy:", res['accuracy'])



"""## Extra

# Importing a library that is not in Colaboratory

To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`.
"""

!pip install matplotlib-venn

!apt-get -qq install -y libfluidsynth1

"""# Install 7zip reader [libarchive](https://pypi.python.org/pypi/libarchive)"""

# https://pypi.python.org/pypi/libarchive
!apt-get -qq install -y libarchive-dev && pip install -U libarchive
import libarchive

"""# Install GraphViz & [PyDot](https://pypi.python.org/pypi/pydot)"""

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install pydot
import pydot

"""# Install [cartopy](http://scitools.org.uk/cartopy/docs/latest/)"""

!pip install cartopy
import cartopy

